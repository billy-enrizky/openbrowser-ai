name: openbrowser-online-grpo-v7
entrypoint: bash -c "python -m infra.eval.scripts.download_datasets --datasets formfactory && python -m infra.training.finetuning.online_grpo_trainer"
containerfile: infra/training/anyscale/Containerfile.online-grpo
compute_config:
  cloud: "Anyscale Cloud"
  head_node:
    instance_type: g5.xlarge
  worker_nodes: []
working_dir: .
excludes:
  - .git
  - .env
  - __pycache__
  - node_modules
  - frontend
  - .cursor
  - presentation
  - data/mind2web/
  - data/webarena/
  - results/
  - outputs/
  - openbrowser_agent_data/
  - data/formfactory/.git/
  - data/formfactory/img/
  - "*.pyc"
env_vars:
  TRAIN_FILE: "data/processed/formfactory_sft_train.jsonl"
  MAX_TRAIN_SAMPLES: "992"
  NUM_EPOCHS: "1"
  SFT_CHECKPOINT_PATH: "/mnt/user_storage/openbrowser/checkpoints/sft"
  # GRPO v7 changes to reduce 62% skip rate:
  # 1. Lower min_reward_variance from 0.01 to 0.001 (capture smaller field_accuracy diffs)
  # 2. Temperature spread 0.4 = rollouts at [0.8, 0.93, 1.07, 1.2] for diversity
  # 3. Longer patience (100 vs 50) to process more of the 992 prompts
  MIN_REWARD_VARIANCE: "0.001"
  TEMPERATURE_SPREAD: "0.4"
  EARLY_STOPPING_PATIENCE: "100"
  EARLY_STOPPING_WINDOW: "30"
  # HF_TOKEN injected from .env at submission time by submit_job.py
max_retries: 1
timeout_s: 172800
tags:
  project: openbrowser
  task: online-grpo-v7
  model: qwen3-8b
